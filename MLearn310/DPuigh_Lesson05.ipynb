{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_The main focus of this assignment is clustering from theoretical as well as practical perspective_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Clustering (Manually)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following dataset, perform the clustering “by hand”:\n",
    "\n",
    "17 28 50 60 80 89 150 167 171 189 \n",
    "1. \tUse the K-means algorithm with K= 3 to cluster the data\n",
    "2. \tUse hierarchical agglomerative clustering with single linkage to cluster the data\n",
    "3. \tUse hierarchical agglomerative clustering with complete linkage to cluster the data\n",
    "4. \tFor K-means What will the final clusters be after 3 iterations if k=3 and the initial centers are 150, 171 and 189"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following dataset, perform the clustering “by hand”:\n",
    "\n",
    "17 28 50 60 80 89 150 167 171 189\n",
    "\n",
    "1. \t**Use the K-means algorithm with K= 3 to cluster the data**\n",
    "\n",
    "    a.  Randomly choose 3 points to be cluster centers: 50, 60, 171.\n",
    "    \n",
    "    b.  v1. Assign each point to cluster center based on least-squared Euclidean distance:\n",
    "        <br />(17,50), (28,50), (50,50), (60,60), (80,60), (89,60), (150,171), (167,171), (171,171), (189,171)\n",
    "        <br />Calculate new centroids: 31.7, 76.3, 169.3\n",
    "\n",
    "    c.  v2. Assign each point to cluster center based on least-squared Euclidean distance:\n",
    "        <br />(17,31.7), (28,31.7), (50,31.7), (60,76.3), (80,76.3), (89,76.3), (150,169.3), (167,169.3), (171,169.3), (189,169.3)\n",
    "        <br />Calculate new centroids: 31.7, 76.3, 169.3\n",
    "\n",
    "    d.  Cluster centroids and assignments haven't changed, so the final assignment is:\n",
    "        <br />Cluster centroids: 0 = 31.7, 1 = 76.3, 2 = 169.3\n",
    "        <br />Cluster assignments: (17,0), (28,0), (50,0), (60,1), (80,1), (89,1), (150,2), (167,2), (171,2), (189,2)\n",
    "\n",
    "\n",
    "2. \t**Use hierarchical agglomerative clustering with single linkage to cluster the data**\n",
    "\n",
    "    a.  Initial clustering: (17) (28) (50) (60) (80) (89) (150) (167) (171) (189)\n",
    "        <br /> (17)<- 11 ->(28)<- 22 ->(50)<- 10 ->(60)<- 20 ->(80)<- 9 ->(89)<- 61 ->(150)<- 17 ->(167)<- 4 ->(171)<- 18 ->(189)\n",
    "\n",
    "    b.  v1 clustering: (17) (28) (50) (60) (80) (89) (150) (167,171) (189)\n",
    "        <br /> (17)<- 11 ->(28)<- 22 ->(50)<- 10 ->(60)<- 20 ->(80)<- 9 ->(89)<- 61 ->(150)<- 17 ->(167,171)<- 18 ->(189)\n",
    "\n",
    "    c.  v2 clustering: (17) (28) (50) (60) (80,89) (150) (167,171) (189)\n",
    "        <br /> (17)<- 11 ->(28)<- 22 ->(50)<- 10 ->(60)<- 20 ->(80,89)<- 61 ->(150)<- 17 ->(167,171)<- 18 ->(189)\n",
    "\n",
    "    d.  v3 clustering: (17) (28) (50,60) (80,89) (150) (167,171) (189)\n",
    "        <br /> (17)<- 11 ->(28)<- 22 ->(50,60)<- 20 ->(80,89)<- 61 ->(150)<- 17 ->(167,171)<- 18 ->(189)\n",
    "\n",
    "    e.  v4 clustering: (17,28) (50,60) (80,89) (150) (167,171) (189)\n",
    "        <br /> (17,28)<- 22 ->(50,60)<- 20 ->(80,89)<- 61 ->(150)<- 17 ->(167,171)<- 18 ->(189)\n",
    "\n",
    "    f.  v5 clustering: (17,28) (50,60) (80,89) (150,167,171) (189)\n",
    "        <br /> (17,28)<- 22 ->(50,60)<- 20 ->(80,89)<- 61 ->(150,167,171)<- 18 ->(189)\n",
    "\n",
    "    g.  v6 clustering: (17,28) (50,60) (80,89) (150,167,171,189)\n",
    "        <br /> (17,28)<- 22 ->(50,60)<- 20 ->(80,89)<- 61 ->(150,167,171,189)\n",
    "\n",
    "    h.  v7 clustering: (17,28) (50,60,80,89) (150,167,171,189)\n",
    "        <br /> (17,28)<- 22 ->(50,60,80,89)<- 61 ->(150,167,171,189)\n",
    "\n",
    "    i.  v8 clustering: (17,28,50,60,80,89) (150,167,171,189)\n",
    "        <br /> (17,28,50,60,80,89)<- 61 ->(150,167,171,189)\n",
    "\n",
    "    j.  v9 clustering: (17,28,50,60,80,89,150,167,171,189)\n",
    "    \n",
    "    k.  Two main clusters with large distance between them: (17,28,50,60,80,89) (150,167,171,189)\n",
    "\n",
    "\n",
    "\n",
    "3. \t**Use hierarchical agglomerative clustering with complete linkage to cluster the data**\n",
    "\n",
    "    a.  Initial clustering: (17) (28) (50) (60) (80) (89) (150) (167) (171) (189)\n",
    "        <br /> (17)<- 11 ->(28)<- 22 ->(50)<- 10 ->(60)<- 20 ->(80)<- 9 ->(89)<- 61 ->(150)<- 17 ->(167)<- 4 ->(171)<- 18 ->(189)\n",
    "        <br /> Smallest distance = 4 between 167 and 171 -> merge these into a cluster (167,171)\n",
    "\n",
    "    b.  v1 clustering: (17) (28) (50) (60) (80) (89) (150) (167,171) (189)\n",
    "        <br /> (17)<- 11 ->(28)<- 22 ->(50)<- 10 ->(60)<- 20 ->(80)<- 9 ->(89)<- 61 ->(150)<- 21 ->(167,171)<- 22 ->(189)\n",
    "\n",
    "    c.  v2 clustering: (17) (28) (50) (60) (80,89) (150) (167,171) (189)\n",
    "        <br /> (17)<- 11 ->(28)<- 22 ->(50)<- 10 ->(60)<- 29 ->(80,89)<- 70 ->(150)<- 21 ->(167,171)<- 22 ->(189)\n",
    "\n",
    "    d.  v3 clustering: (17) (28) (50,60) (80,89) (150) (167,171) (189)\n",
    "        <br /> (17)<- 11 ->(28)<- 32 ->(50,60)<- 39 ->(80,89)<- 70 ->(150)<- 21 ->(167,171)<- 22 ->(189)\n",
    "\n",
    "    e.  v4 clustering: (17,28) (50,60) (80,89) (150) (167,171) (189)\n",
    "        <br /> (17,28)<- 42 ->(50,60)<- 39 ->(80,89)<- 70 ->(150)<- 21 ->(167,171)<- 22 ->(189)\n",
    "\n",
    "    f.  v5 clustering: (17,28) (50,60) (80,89) (150,167,171) (189)\n",
    "        <br /> (17,28)<- 42 ->(50,60)<- 39 ->(80,89)<- 70 ->(150,167,171)<- 39 ->(189)\n",
    "\n",
    "    g.  v6 clustering: (17,28) (50,60,80,89) (150,167,171,189)\n",
    "        <br /> (17,28)<- 72 ->(50,60,80,89)<- 139 ->(150,167,171,189)\n",
    "\n",
    "    h.  v7 clustering: (17,28,50,60,80,89) (150,167,171,189)\n",
    "        <br /> (17,28,50,60,80,89)<- 172 ->(150,167,171,189)\n",
    "\n",
    "    i.  v8 clustering: (17,28,50,60,80,89,150,167,171,189)\n",
    "        <br /> (17,28,50,60,80,89,150,167,171,189)\n",
    "\n",
    "    j.  Two main clusters with large distance between them: (17,28,50,60,80,89) (150,167,171,189)\n",
    "\n",
    "\n",
    "\n",
    "4. \t**For K-means What will the final clusters be after 3 iterations if k=3 and the initial centers are 150, 171 and 189**\n",
    "\n",
    "    v1. Assign each point to cluster center:\n",
    "        <br />(17,0), (28,0), (50,0), (60,0), (80,0), (89,0), (150,0), (167,1), (171,1), (189,2)\n",
    "        <br />New cluster centers: 0 = 67.7, 1 = 169, 2 = 189\n",
    "\n",
    "    v2. Assign each point to cluster center:\n",
    "        <br />(17,0), (28,0), (50,0), (60,0), (80,0), (89,0), (150,1), (167,1), (171,1), (189,2)\n",
    "        <br />New cluster centers: 0 = 54, 1 = 162.7, 2 = 189\n",
    "\n",
    "    v3. Assign each point to cluster center:\n",
    "        <br />(17,0), (28,0), (50,0), (60,0), (80,0), (89,0), (150,1), (167,1), (171,1), (189,2)\n",
    "        <br />New cluster centers: 0 = 54, 1 = 162.7, 2 = 189"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note: Do not write code to answer this question_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Clustering (Code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the dataset of accepted papers at the AAAI 2014 conference to find clusters of papers using K-Means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Relevant libraries\n",
    "import sklearn as sk\n",
    "import urllib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# URL for the AAAI (UW Repository)\n",
    "url = \"AAAI2014AcceptedPapers.csv\"\n",
    "\n",
    "# download the file\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(min_df=0.05, max_df=0.2, max_features=250)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['abstract'])\n",
    "terms = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1) Vary the number of K from 2 to 6 and show if the results vary and assess the clusters obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************************************************\n",
      "Using K = 2 clusters\n",
      "Cluster 0, size = 254, words:\n",
      "['time', 'search', 'planning', 'number', 'agents', 'set', 'over', 'first', 'when', 'game'] \n",
      "\n",
      "Cluster 1, size = 144, words:\n",
      "['models', 'classification', 'users', 'information', 'image', 'supervised', 'multi', 'tasks', 'training', 'task'] \n",
      "\n",
      "**********************************************************************\n",
      "Using K = 3 clusters\n",
      "Cluster 0, size = 121, words:\n",
      "['models', 'users', 'probabilistic', 'user', 'social', 'prediction', 'information', 'time', 'knowledge', 'large'] \n",
      "\n",
      "Cluster 1, size = 200, words:\n",
      "['search', 'planning', 'number', 'agents', 'time', 'game', 'graph', 'constraints', 'set', 'given'] \n",
      "\n",
      "Cluster 2, size = 77, words:\n",
      "['domain', 'classification', 'supervised', 'multi', 'tasks', 'label', 'feature', 'labels', 'target', 'task'] \n",
      "\n",
      "**********************************************************************\n",
      "Using K = 4 clusters\n",
      "Cluster 0, size = 58, words:\n",
      "['agents', 'search', 'agent', 'preferences', 'when', 'strategy', 'design', 'functions', 'number', 'task'] \n",
      "\n",
      "Cluster 1, size = 89, words:\n",
      "['users', 'models', 'social', 'information', 'user', 'probabilistic', 'networks', 'time', 'online', 'knowledge'] \n",
      "\n",
      "Cluster 2, size = 117, words:\n",
      "['classification', 'multi', 'domain', 'image', 'feature', 'supervised', 'sparse', 'function', 'label', 'datasets'] \n",
      "\n",
      "Cluster 3, size = 134, words:\n",
      "['planning', 'number', 'constraints', 'graph', 'game', 'given', 'set', 'complexity', 'system', 'time'] \n",
      "\n",
      "**********************************************************************\n",
      "Using K = 5 clusters\n",
      "Cluster 0, size = 86, words:\n",
      "['domain', 'knowledge', 'planning', 'language', 'tasks', 'task', 'system', 'target', 'natural', 'domains'] \n",
      "\n",
      "Cluster 1, size = 47, words:\n",
      "['users', 'social', 'user', 'online', 'information', 'time', 'prediction', 'different', 'image', 'features'] \n",
      "\n",
      "Cluster 2, size = 103, words:\n",
      "['models', 'multi', 'classification', 'selection', 'labels', 'feature', 'probabilistic', 'training', 'supervised', 'image'] \n",
      "\n",
      "Cluster 3, size = 51, words:\n",
      "['agents', 'agent', 'behavior', 'strategy', 'preferences', 'game', 'when', 'design', 'functions', 'any'] \n",
      "\n",
      "Cluster 4, size = 111, words:\n",
      "['search', 'number', 'time', 'graph', 'constraints', 'all', 'given', 'first', 'solution', 'solutions'] \n",
      "\n",
      "**********************************************************************\n",
      "Using K = 6 clusters\n",
      "Cluster 0, size = 51, words:\n",
      "['users', 'user', 'social', 'time', 'online', 'temporal', 'prediction', 'information', 'behavior', 'different'] \n",
      "\n",
      "Cluster 1, size = 100, words:\n",
      "['models', 'quality', 'system', 'probabilistic', 'provide', 'evaluation', 'only', 'inference', 'time', 'optimal'] \n",
      "\n",
      "Cluster 2, size = 63, words:\n",
      "['agents', 'game', 'agent', 'preferences', 'strategy', 'functions', 'number', 'social', 'form', 'when'] \n",
      "\n",
      "Cluster 3, size = 67, words:\n",
      "['search', 'planning', 'constraints', 'graph', 'set', 'local', 'all', 'linear', 'into', 'constraint'] \n",
      "\n",
      "Cluster 4, size = 43, words:\n",
      "['domain', 'tasks', 'knowledge', 'task', 'target', 'source', 'language', 'classification', 'framework', 'feature'] \n",
      "\n",
      "Cluster 5, size = 74, words:\n",
      "['multi', 'classification', 'image', 'feature', 'selection', 'low', 'labels', 'sparse', 'matrix', 'dimensional'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in range(2,7):\n",
    "    print(\"*\" * 70)\n",
    "    print(\"Using K = %d clusters\" % (k))\n",
    "\n",
    "    km = KMeans(n_clusters=k)#, verbose=False)\n",
    "    km = km.fit(tfidf_matrix)\n",
    "\n",
    "    centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "    \n",
    "    labels = km.labels_\n",
    "\n",
    "    for c in range(len(centroids)):\n",
    "        cluster_size = len([l for l in labels if l==c])\n",
    "        print(\"Cluster %d, size = %d, words:\" % (c, cluster_size))\n",
    "        indices = centroids[c,:10]\n",
    "        top = [terms[i] for i in indices]\n",
    "        print(top,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2) Make a case regarding which clusters ‘make sense’ e.g., is there a cluster were papers on reinforcement learning are together vs. another cluster which has papers on deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the clusters do make sense and show a lot of promise. Many of the clusters have repetitions of very similar words, e.g., \"task\"/\"tasks\", \"probability\"/\"probabilistic\". We also see common clustering between groups of words that also make a lot of intuitive sense together, independent of the number of clusters, e.g., \"user\"/\"social\", \"time\"/\"temporal\", \"sparse\"/\"low\". When using only two clusters, there is not a lot of opportunity to see important distinctions between words in the two different groups. The word groupings are most interesting when there are four, five, or six clusters. Then we have groups of words that go together based on similar type of problems or solutions involving machine learning and/or deep learning, e.g., \"classification\"/\"labels\"/\"image\"/\"training\"/\"testing\", or \"domain\"/\"knowledge\"/\"task\"/\"framework\", or reinforcement learning, \"agaent\"/\"task\"/\"game\"/\"strategy\"/\"function\"/\"behavior\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
