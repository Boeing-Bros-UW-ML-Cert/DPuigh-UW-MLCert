{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Assignment 10: Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Dataset(s) needed: MNIST (\"Modified National Institute of Standards and Technology\") dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the MNIST dataset\n",
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Q.1. Split the data into a training set and a test set (take the first 60,000 instances for training, and the remaining 10,000 for testing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (60000,) (10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X = pd.DataFrame(mnist.data)\n",
    "y = pd.Series(mnist.target).astype(int)\n",
    "\n",
    "num = 60000\n",
    "\n",
    "X_train, y_train, X_test, y_test = X.iloc[:num], y.iloc[:num], X.iloc[num:], y.iloc[num:]\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q.2. Train a Logistic Regression classifier on the dataset and see how long it takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 17.48s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "\n",
    "log_clf = LogisticRegression(solver=\"lbfgs\", multi_class=\"multinomial\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the classifier\n",
    "lr_model = log_clf.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "duration_full = end_time - start_time\n",
    "\n",
    "print(\"Training took {:.2f}s\".format(duration_full))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q.3. Evaluate the resulting model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on the test set:\n",
      "\n",
      " Confusion matrix:\n",
      " [[ 963    0    0    3    1    3    4    4    2    0]\n",
      " [   0 1112    4    2    0    1    3    2   11    0]\n",
      " [   3   10  926   15    6    4   15    8   42    3]\n",
      " [   4    1   21  916    1   26    3    9   22    7]\n",
      " [   1    1    7    3  910    0    9    7   10   34]\n",
      " [  11    2    1   33   11  776   11    6   35    6]\n",
      " [   9    3    7    3    7   16  910    2    1    0]\n",
      " [   1    6   24    5    7    1    0  951    3   30]\n",
      " [   8    7    6   23    6   26   10   10  869    9]\n",
      " [   9    7    0   11   25    6    0   22    7  922]]\n",
      "\n",
      " Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.98      0.97       980\n",
      "          1       0.97      0.98      0.97      1135\n",
      "          2       0.93      0.90      0.91      1032\n",
      "          3       0.90      0.91      0.91      1010\n",
      "          4       0.93      0.93      0.93       982\n",
      "          5       0.90      0.87      0.89       892\n",
      "          6       0.94      0.95      0.95       958\n",
      "          7       0.93      0.93      0.93      1028\n",
      "          8       0.87      0.89      0.88       974\n",
      "          9       0.91      0.91      0.91      1009\n",
      "\n",
      "avg / total       0.93      0.93      0.93     10000\n",
      "\n",
      "\n",
      " Accuracy score = 0.925\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score \n",
    "\n",
    "y_test_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "print(\"Performance on the test set:\")\n",
    "print(\"\\n Confusion matrix:\\n\", confusion_matrix(y_test, y_test_pred_lr))  \n",
    "print(\"\\n Classification report:\\n\", classification_report(y_test, y_test_pred_lr))\n",
    "print(\"\\n Accuracy score = %.3f\" % (accuracy_score(y_test, y_test_pred_lr)))\n",
    "\n",
    "accuracy_full = accuracy_score(y_test, y_test_pred_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Q.4. Use PCA to reduce the dataset's dimensionality, with an explained variance ratio of 95%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.95, svd_solver='full')\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components chosen = 154, Total explained variance ratio = 0.950\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of components chosen = %d, Total explained variance ratio = %.3f\" % (pca.n_components_, \n",
    "                                                                                   pca.explained_variance_ratio_.cumsum()[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Q.5. Train a new Logistic Regression classifier on the reduced dataset and see how long it takes. Was training much faster? Explain your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 7.30s\n"
     ]
    }
   ],
   "source": [
    "log_pca = LogisticRegression(solver=\"lbfgs\", multi_class=\"multinomial\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the classifier\n",
    "lr_pca_model = log_pca.fit(X_train_pca, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "duration_pca = end_time - start_time\n",
    "\n",
    "print(\"Training took {:.2f}s\".format(duration_pca))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q.6. Evaluate the new classifier on the test set: how does it compare to the previous classifier? Discuss the speed / accuracy trade-off and in which case you'd prefer a very slight drop in model performance for a x-time speedup in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on the test set:\n",
      "\n",
      " Confusion matrix:\n",
      " [[ 959    0    1    1    2    2    7    6    1    1]\n",
      " [   0 1108    2    2    1    2    4    2   14    0]\n",
      " [  10   11  933   11    8    4   12    8   27    8]\n",
      " [   4    1   24  910    3   25    2   12   18   11]\n",
      " [   2    3    4    2  916    0    9    2   10   34]\n",
      " [   9    4    4   32   11  765   15   10   34    8]\n",
      " [   9    6    8    0    9   12  909    3    2    0]\n",
      " [   3    9   19    5    8    1    0  951    0   32]\n",
      " [   8   14   10   26   11   24   14   15  843    9]\n",
      " [  12    6    1   11   36    5    1   24    6  907]]\n",
      "\n",
      " Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.98      0.96       980\n",
      "          1       0.95      0.98      0.96      1135\n",
      "          2       0.93      0.90      0.92      1032\n",
      "          3       0.91      0.90      0.91      1010\n",
      "          4       0.91      0.93      0.92       982\n",
      "          5       0.91      0.86      0.88       892\n",
      "          6       0.93      0.95      0.94       958\n",
      "          7       0.92      0.93      0.92      1028\n",
      "          8       0.88      0.87      0.87       974\n",
      "          9       0.90      0.90      0.90      1009\n",
      "\n",
      "avg / total       0.92      0.92      0.92     10000\n",
      "\n",
      "\n",
      " Accuracy score = 0.920\n"
     ]
    }
   ],
   "source": [
    "y_test_pca_pred_lr = lr_pca_model.predict(X_test_pca)\n",
    "\n",
    "print(\"Performance on the test set:\")\n",
    "print(\"\\n Confusion matrix:\\n\", confusion_matrix(y_test, y_test_pca_pred_lr))  \n",
    "print(\"\\n Classification report:\\n\", classification_report(y_test, y_test_pca_pred_lr))\n",
    "print(\"\\n Accuracy score = %.3f\" % (accuracy_score(y_test, y_test_pca_pred_lr)))\n",
    "\n",
    "accuracy_pca = accuracy_score(y_test, y_test_pca_pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: full logistic regression / PCA logistic regression = 17.48s / 7.30s = 2.4\n",
      "Accuracy: full logistic regression / PCA logistic regression = 0.9255 / 0.9201 = 1.006\n"
     ]
    }
   ],
   "source": [
    "print(\"Training time: full logistic regression / PCA logistic regression = %.2fs / %.2fs = %.1f\" % (duration_full, duration_pca, \n",
    "                                                                                                    duration_full/duration_pca))\n",
    "\n",
    "print(\"Accuracy: full logistic regression / PCA logistic regression = %.4f / %.4f = %.3f\" % (accuracy_full, accuracy_pca, \n",
    "                                                                                             accuracy_full/accuracy_pca))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the full logistic regression model with 784 features results in less than a 1% increase in accuracy over the PCA logistic regression model with 154 features, but it takes 2.4 times longer to train. That increase in accuracy is completely negligible when compared to the training time increase. The training time for the full model was not so significant in this case, but as the dataset increases and models become more complex, this improvement in training time could save hours or days."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
